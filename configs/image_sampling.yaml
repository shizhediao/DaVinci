train_file: [
    "hdfs://haruna/home/byte_ailab_litg/user/zhangxinsong/datasets/vlm/coco_vg_bs64",
               ]
val_file: './data/coco_val_image_generation.json'
c4_train_file: ["hdfs://haruna/home/byte_ailab_litg/user/zhangxinsong/datasets/c4/en_split"]
image_root: './images/coco/'

image_name: "binary"
caption_name: "desc"
train_file_tokenized: false
train_dataset_size: 1335283
checkpoint_frequent: 10000

bert_config: 'configs/config_bert.json'
init_encoder: False
init_decoder: False

image_res: 256
second_input_size: 256
vision_width: 1024
embed_dim: 256
batch_size: 1
temp: 0.07
num_images: 128
image_per_round: 8

context_max_length: 25
max_length: 257
enc_max_words: 96
dec_max_words: 256
enc_max_tokens: 256
dec_max_tokens: 256
enc_dec_max_words: 512
c4_alpha: 1

num_beams: 1
temperature: 1.0
top_k: 4000
top_p: 0.9
repetition_penalty: 1
length_penalty: 1
early_stopping: false
num_return_sequences: 1
eos: '[SEP]'

# dalle
discrete_vae_weight_path: "vqgan_ckpt"
discrete_vae_type: "vqgan"

optimizer: {opt: adamW, lr: 2e-4, weight_decay: 0.01}
schedular: {sched: linear, last_epoch: -1, epochs: 80, warmup_epochs: 4}
accelerator: {SYNCBN: false, FP16_OPT_LEVEL: O1, FP16_LOSS_SCALE: dynamic, RNG_SEED: 42, GRAD_ACCUMULATE_STEPS: 8, CLIP_GRAD_NORM: 1.0}